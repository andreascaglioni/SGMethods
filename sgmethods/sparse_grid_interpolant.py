"""
The core module of SGmethods. It contains the implementation of sparse grid
interpolation in a class.
"""

from math import sqrt
from multiprocessing import Pool
import numpy as np
from numpy.linalg import norm as norm_l2
from sgmethods.tp_interpolants import TPPwLinearInterpolator
from sgmethods.nodes_tp import tp_knots
from sgmethods.tp_interpolant_wrapper import TPInterpolatorWrapper
from sgmethods.multi_index_sets import compute_mid_set_fast


def build_interpolant_n_nodes(profit, dim_y, nodes, lev2knots, n_sg, f=sqrt(2.0)):
    """
    Builds a sparse grid interpolant with at least n_sg nodes for a given profit function.
    Args:
        profit (callable): Function to evaluate profit, input a np.array.
        dim_y (int): Dimension of the input space.
        nodes (array-like): Nodes for the sparse grid.
        lev2knots (callable): Function mapping levels to knots.
        n_sg (int): Minimum number of sparse grid nodes required.
        f (float, optional): Reduction factor for profit threshold. Default sqrt(2.).
    Returns:
        SGInterpolant: Interpolant object with at least n_sg nodes.
    """

    reduce_p = True
    min_profit = 0.99 * profit(np.array([[0]]))
    while reduce_p:
        mid_set = compute_mid_set_fast(profit, min_profit, dim_y)
        Interp = SGInterpolant(mid_set, nodes, lev2knots)
        if Interp.SG.shape[0] >= n_sg:
            break
        min_profit /= f
    return Interp



class SGInterpolant:
    """Sparse grid interpolant class. It stores all relevant information to
    define it like multi-index set, 1D notes etc.
    It automatically computes the sparse grid and inclusion-exclusion
    coefficients upon initialization.
    It allows to interpolate high dimensinal functions on the sparse grid.
    """

    def __init__(
        self,
        mid_set,
        knots,
        lev2knots,
        tp_interpolant=TPPwLinearInterpolator,
        n_parallel=1,
        verbose=True,
    ):
        """Initialize data, compute inclusion-exclusion coeff.s, sparse grid

        Args:
            mid_set (numpy.ndarray[int]): 2D array. Multi-index set. NB must be
                downward closed.
            knots (Callable[[int], numpy.ndarray[double]]): Get the nodes vector
                with the given number of nodes.
            lev2knots (Callable[[int], int]): Given a level >=0, returns the
                corresponding number of nodes >0.
            tp_interpolant (Class TPInterpolant, optional): One of the classes in the module
                tp_interpolants. (e.g. TPPwLinearInterpolator). The
                user can also define their own class following the instructions
                in the same module. Defaults to a piecewise-linear inteprolant.
            n_parallel (int, optional): Number of parallel computations.
                Defaults to 1.
            verbose (bool, optional): Verbose output. Defaults to True.
        """

        self.verbose = verbose
        self.mid_set = mid_set  # Multi-index set

        # The number of multi-indices and their dimensionality
        self.card_mid_set, self.N = mid_set.shape

        # Knot function # NB need knots[1] = np.array([0.]) to increase # dim.s
        self.knots = knots

        # Level-to-knot function # NB need lev2knots(0)=1 to increase number of dim.s
        self.lev2knots = lev2knots

        self.tp_interpolant = tp_interpolant  # TP interpolant Class
        self.n_parallel = n_parallel


        # -------------- Members to compute in setup_interpolant ------------- #
        # list[np.ndarray[float]] of multi-indices with non-zero combination_coefficient
        # NB [0] is included if and onyl if Lambda = [[0]]
        # TODO change to only INDICES of active mids in midset?
        self.active_mids = []

        # list[(]int] of inclusion-exclusion coefficients for active mids (others are 0)
        self.combination_coeffs = []

        # List of ``active TP nodes'', i.e. self.active_tp_nodes_list[i] are the nodes of the TP interpolant defined by self.active_mids[i]. self.active_tp_nodes_list[i] is generated by nodes_tp.tp_knots. list[tuple[np.ndarray[float]]]
        self.active_tp_nodes_list = []

        # For each TP interpolant defined by self.active_mids, the dimensions with more than 1 node (recall that if there is only 1 node, it is 0)
        self.active_dims = []

        # Map each TP grid node to a corresponding SG node. Used to map collocations samples as:
        #       f_on_TP = f_on_SG[self.map_curr_tp_to_SG[i], :]
        # list[numpy.ndarray[float]], map_tp_to_SG[i] has shape tuple(num_nodes_active_dirs)
        self.map_tp_to_SG = []
        self.setup_interpolant()

        # ------------------ Members to compute in setup_SG ------------------ #
        self.SG = []  # np array of shape (#colloc. pts, N)
        self.num_nodes = 0  # number of sparse grid nodes

        # A list of cardinality = # active mids. where_tp_nu[i] is numpy.ndarray[int] of shape (#\YY_{\nu}, ) containing the indices in self.SG correpsonding to the nodes in the TP grid corresponding to \nu (\nu is the i-th active mid)
        self.where_tp = []

        self.setup_SG()

    def setup_interpolant(self):
        """Computes and saves in class attributes some important quantities:
        combination coefficients, active multi-indicies, active TP dimensions,
        active TP nodes, map TP to SG nodes based on the multi-index set, the
        nodes and the level-to-knot function.

        Args:
            None

        Returns:
            None
        """

        # Pre-comute ``bookmarks'' to speed up computation of combination coefficients
        bks = np.unique(self.mid_set[:, 0], return_index=True)[1]
        bk = np.hstack((bks[2:], np.array([self.card_mid_set, self.card_mid_set])))

        for n in range(self.card_mid_set):
            current_mid = self.mid_set[n, :]

            # Compute combination coefficients
            combin_coeff = 1
            range_ids = bk[current_mid[0]]
            mids_diff = self.mid_set[(n + 1) : (range_ids), :] - current_mid
            is_bin = np.all(np.logical_and(mids_diff >= 0, mids_diff <= 1), axis=1)
            binary_rows = mids_diff[is_bin]
            combi_elementary = np.power(-1, np.sum(binary_rows, axis=1))
            combin_coeff += np.sum(combi_elementary)

            # Set some variables only for active multi-indices (see def in __init__)
            if combin_coeff != 0:
                self.combination_coeffs.append(combin_coeff)
                self.active_mids.append(current_mid)

                # Number of nodes in each direction
                num_nodes_arr = self.lev2knots(current_mid).astype(int)

                # Dimensions with more than 1 node
                active_dims = np.asarray(num_nodes_arr > 1).nonzero()

                self.active_dims.append(active_dims[0])
                num_nodes_active_dirs = num_nodes_arr[active_dims]
                
                # Handle case nu=0 (constant)
                if num_nodes_active_dirs.shape[0] == 0:  
                    num_nodes_active_dirs = np.array([1])
                
                self.active_tp_nodes_list.append(
                    tp_knots(self.knots, num_nodes_active_dirs)
                )

                # Allocate self.map_tp_to_SG
                # For each active tensor product interpolant, relate each TP node to an index of the sparse grid self.SG.
                # list[np.ndarray[int]]
                # self.map_tp_to_SG[i] is numpu.ndarray[int] with shape (# nodes d0, # nodes d1, ..., # nodes dN)
                # For TP interpolant, interpolated values are stored in matrix of this same shape
                shp = np.ndarray(tuple(num_nodes_active_dirs), dtype=int)
                self.map_tp_to_SG.append(shp)  # only allocated

    def setup_SG(self):
        """Computes and saves in class attributes some important quantities:
        SG (sparse grid), num_nodes, map_tp_to_SG, where_tp_nu
        based on active_tp_nodes_list.
        """

        where_tp = []
        SG = np.array([]).reshape((0, self.N))

        for idx_active, curr_active_tp_nodes in enumerate(self.active_tp_nodes_list):
            curr_active_dims = self.active_dims[idx_active]

            # NB "*" is "unpacking" operator (return comma-separated list)
            mesh_grid = np.meshgrid(*curr_active_tp_nodes, indexing="ij")

            it = np.nditer(mesh_grid[0], flags=["multi_index"])
            for x in it:
                curr_node_active_dims = [
                    mesh_grid[j][it.multi_index] for j in range(len(mesh_grid))
                ]
                # complete it with 0s in inactive dimensions
                curr_node = np.zeros(self.N)
                curr_node[curr_active_dims] = curr_node_active_dims

                # Check if curr_node is in SG
                check = np.where(np.sum(np.abs(SG - curr_node), axis=1) < 1.0e-10)[0]
                found = check.shape[0]

                assert found <= 1, "The sparse grid has repeated nodes"

                if found:  # if found, add the index to mapTPtoSG[n]
                    self.map_tp_to_SG[idx_active][it.multi_index] = check[0]
                else:  # if not found, add it to sparse grid, add to mapTPtoSG
                    SG = np.vstack((SG, np.array(curr_node)))
                    self.map_tp_to_SG[idx_active][it.multi_index] = SG.shape[0] - 1

            # based on self.map_tp_to_SG[idx_active], compute new self.where_tp_in_sg[idx_active]
            where_tp.append(self.map_tp_to_SG[idx_active].flatten())

        self.SG = SG
        self.num_nodes = SG.shape[0]
        self.where_tp = where_tp

    # TODO remove dimF from signature; check all other scripts
    def sample_on_SG(self, f, dim_f=None, old_xx=None, old_samples=None):
        """Sample a given function on the sparse grid.

        Optionally recycle previous samples stored e.g. from a previous
        interpolation. The class also takes care automatically of the case in
        which the sparse grid has increased dimension (number of approcimated
        scaar parameters).
        The class first checks whether or not there is anything to recycle, then
        it sample new values.

        NB The class assumes ``f`` takes as input a numpy.ndarray[float] of
        parameters. The 1st output is assumed to be a numpy.ndarray[float] or a
        float (in this case, it is transformed into a 1-entry
        numpy.ndarray[float]).

        Args:
            f (Callable[[numpy.ndarray[float]], numpy.ndarray[float]]): The
                function to interpolate.
            dim_f (int, optional): Dimensinoality codomain of ``f``. Defaults to
                None.
            old_xx (numpy.ndarray[float], optional): 2D array.  Each row is a
                parametric point Defaults to None.
            old_samples (numpy.ndarray[float], optional): 2D array. Each row
                corresponds to a row of old_xx. Defaults to None.

        Returns:
            numpy.ndarray[float]: 2D array. Each row
            is the value of ``f`` on a sparse grid (``self.SG``) point.
        """


        # Input check: old_xx is None iff old_sampels is None
        assert (old_xx is None and old_samples is None) or (old_xx is not None and old_samples is not None), f"Old xx and samples don't match: \nold_xx: {old_xx} \nold_samples: {old_samples}"
        
        # Find dimension values of f form old_samples (if available) or sampling a new f
        if old_samples is not None:  # If old samples provided, just use that
            dim_f = old_samples.shape[1]
        else:  # No recycling will happen. Compute f on 1st SG node
            f_y0 = np.atleast_1d(f(self.SG[0]))
            assert len(f_y0.shape) == 1, "Only 1D function values are supported."
            dim_f = f_y0.size

        # Initialize output array: each row is 1 samples
        f_on_SG = np.zeros((self.num_nodes, dim_f))

        # If None, turn old_xx and old_samples into np arrays with 0 rows
        if old_xx is None:
            old_xx = np.zeros((0, self.N))
            old_samples = np.zeros((0, dim_f))

        assert old_xx.shape[0] == old_samples.shape[0], "old_xx and old_samples must have same number of rows"

        # If old_xx has smaller dimension than the sparse grid: 0-extend it
        if old_xx.shape[1] < self.N:
            filler = np.zeros((old_xx.shape[0], self.SG.shape[1] - old_xx.shape[1]))
            old_xx = np.hstack((old_xx, filler))

        # If old_xx has larger dimension than the sparse grid: Truncate it
        elif old_xx.shape[1] > self.N:
            curr_dim = self.N
            tail_norm = norm_l2(old_xx[:, curr_dim::], ord=1, axis=1).astype(int)
            # Can recycle old sample only if removed entries=0. Discart others.
            idxs_valid_entries = np.where(tail_norm == 0)[0]
            old_xx = old_xx[idxs_valid_entries, 0 : self.N]
            old_samples = old_samples[idxs_valid_entries]
      
        # Fill f_on_SG
        
        # Find samples to load from old_samples. Store the other nodes to compute later
        n_recycle = 0
        idxs_nodes_to_compute = []
        for idx in range(self.num_nodes):
            curr_node = self.SG[idx, :]
            # found = np.where(norm_l2(old_xx - curr_node, 1, axis=1) < 1.0e-10)[0]
            node_in_old_xx = norm_l2(old_xx - curr_node, 1, axis=1) < 1.0e-10
            found = np.asarray(node_in_old_xx).nonzero()[0]
            
            assert found.size < 2, f"Found curr_node {curr_node} in positions {found} of old_samples. old_samples should not have repetitions."
            
            if found.size > 0:
                n_recycle += 1
                f_on_SG[idx] = old_samples[found, :]
            else:
                idxs_nodes_to_compute.append(idx)

        if self.verbose:
            n_dis = old_xx.shape[0] - n_recycle
            n_sam = self.SG.shape[0] - n_recycle
            print(f"Recycle {n_recycle}; Discart {n_dis}; Sample {n_sam}", flush=True)

        # If old_samples is None, add to f_on_SG the f_y0 computed above
        if old_samples is None and len(idxs_nodes_to_compute) > 0:
            f_on_SG[idxs_nodes_to_compute[0]] = f_y0
            idxs_nodes_to_compute.pop(0)
        
        if len(idxs_nodes_to_compute) > 0:
            if self.n_parallel == 1:
                print("Sample serially", len(idxs_nodes_to_compute), "snapshots")
                for idx in idxs_nodes_to_compute:
                    print(idx, "| ", end="")
                    f_on_SG[idx, :] = f(self.SG[idx])
                print("")
            elif self.n_parallel > 1:
                print("Sample in parallel with", self.n_parallel, "processes")
                pool = Pool(self.n_parallel)
                tmp = np.array(pool.map(f, idxs_nodes_to_compute))
                pool.join()
                pool.close()
                if len(tmp.shape) == 1:
                    tmp = tmp.reshape((-1, 1))
                f_on_SG[idxs_nodes_to_compute, :] = tmp
            else:
                raise ValueError('self.NParallel not int >= 1"')

        
        return f_on_SG

    def interpolate(self, x_new, f_on_SG):
        """Evaluate the interpolant on new parametric points.

        Args:
            x_new (numpy.ndarray[float]): 2D array. New parametric points where
                to interpolate. Each row is a point.
            f_on_SG (numpy.ndarray[float]): 2D array. Values of function on the
                sparse grid. Each row is a value corresponding to a parametric
                point in the sparse grid ``self.SG``.

        Returns:
            numpy.ndarray[float]: 2D array. Values of the interpolant of f on
            ``x_new``. Each row is a value corresponds to the parameter stored
            in the same row of ``x_new``.
        """

        out = np.zeros((x_new.shape[0], f_on_SG.shape[1]))
        for n, mid in enumerate(self.active_mids):
            curr_active_nodes_tuple = self.active_tp_nodes_list[n]
            curr_active_dims = self.active_dims[n]
            map_curr_tp_to_SG = self.map_tp_to_SG[n]
            # output is a matrix of shape = shape(mapCurrTPtoSG) + (dimF,)
            f_on_curr_tp_grid = f_on_SG[map_curr_tp_to_SG, :]
            tp_interpolant = TPInterpolatorWrapper(
                curr_active_nodes_tuple,
                curr_active_dims,
                f_on_curr_tp_grid,
                self.tp_interpolant,
            )
            out = out + self.combination_coeffs[n] * tp_interpolant(x_new)
        return out
